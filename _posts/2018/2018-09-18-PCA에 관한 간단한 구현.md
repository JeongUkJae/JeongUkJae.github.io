---
layout: post
title: "PCA에 관한 간단한 구현"
tags:
---

서울시립대학교에서 18학년 2학기에 수강하는 기계학습개론 과목에 대해서 과제, 공부 자료 등을 정리하고 있는데, PCA[^PCA]에 관한 이론을 배워서 그에 대한 간단한 구현을 해봤다.

[2d에서 1d로 줄이는 스크립트](https://github.com/JeongUkJae/introduction-to-machine-learning-assignments/blob/master/class/PCA-2d-to-1d.ipynb)와 [3d에서 2d로 줄이는 스크립트](https://github.com/JeongUkJae/introduction-to-machine-learning-assignments/blob/master/class/PCA-3d-to-2d.ipynb)이다.

vector들을 mean값의 각 element들을 0으로 맞추고, covariance의 eigen vector와 eigen value들을 구한다. 그 후 eigen value가 큰 순서대로 eigen vector를 축으로 데이터들을 변환한다.

numpy와 python을 이용해서 구현을 했고, jupyter notebook을 이용했다.

2d에서 1d로 줄이는 스크립트의 결과는 알아보기 쉬웠지만, 3d에서 2d로 줄이는 스크립트의 결과는 다소 알아보기 어려웠다.

[^PCA]: [https://en.wikipedia.org/wiki/Principal_component_analysis](https://en.wikipedia.org/wiki/Principal_component_analysis) 간단한 이론은 이 페이지를 참고하길 바란다.
