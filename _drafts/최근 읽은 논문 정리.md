---
title: "최근 읽은 논문 정리"
layout: post
tags:
  - paper
---

경량화 & 작은 모델에서 잘 돌아갈 수 있는 기법을 위주로 논문을 살펴보았다.

## [AIN: Fast and Accurate Sequence Labeling with Approximate Inference Network](https://arxiv.org/pdf/2009.08229.pdf)

* EMNLP 2020
* CRF는 sequential computation이 존재하기 때문에 parallelization이 힘들다.
* Sequence Labeling 문제(NER, POS Tagging)에서 BiLSTM - CRF가 가장 좋은 모델이라 알려져있다.
  * CRF에 대해서는 [Lafferty et al., 2001](https://repository.upenn.edu/cgi/viewcontent.cgi?article=1162&context=cis_papers)를 참고가능할 듯
* 여기서 속도를 향상하는 방법은 아래정도
  * BiLSTM을 CNN으로 교체 ([Strubell et al., 2017](https://www.aclweb.org/anthology/D17-1283/))
  * Encoder에 해당하는 Embedding - BiLSTM을 작은 모델로 Distillation ([Tsai et al., 2019](https://www.aclweb.org/anthology/D19-1374/))
* 하지만 위 두 방법 모두 CRF를 교체한 것이 아니라 다른 모델 부분을 교체한 것인데, 정작 병목은 CRF에도 있기 떄문에 CRF를 교체
* Mean-Field Variational Inference (MFVI)를 적용해서 linear chain CRF를 교체
* binary feature를 사용하는 CRF를 transition score만을 저장하는 matrix하나와 input sentence의 contextual representation의 matmul 결과 값을 쓴다.
* CRF와 비슷한 성능을 보이면서 BiLSTM, 128 words 길이에서 4배 이상빠른 속도를 보여준다.
